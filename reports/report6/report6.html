<html>
	<head>

	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">

	</head>

	<body>
		<h1> Relatório lab 6 </h1>

		<h2> Grupo </h2>

		<p>Leonardo Di Credico </p>

		<p>Anthony Hlebania</p>

		<p>Fernando Hiroaki Suzuki</p>

		<p>Fernando Astolfo Dos Santos</p>
		
		<h2> 1.Introdução </h2>

		<p>Features são pontos distintivos em imagens ou quadros de vídeo, essenciais para tarefas de visão computacional. Nesta aula, estudamos três métodos de 
			detecção de Features: Harris Corner Detection, Shi-Tomasi Corner Detector e Scale-Invariant Feature Transform (SIFT).</p>

		<p>O material de estudo incluiu teoria sobre Features e tutoriais para implementar os exercícios práticos em Python utilizando a biblioteca OpenCV. 
			Foram realizados experimentos de detecção de Features em imagens salvas anteriormente, bem como imagens da webcam. Os resultados foram analisados 
			para cada método de detecção e diferentes cenários, incluindo rostos de integrantes do grupo e um tabuleiro de xadrez preto e branco.</p>
		
		<p>O objetivo deste relatório é compreender a importância das Features no processamento de vídeo, avaliar a eficácia dos métodos de detecção e explorar 
			suas aplicações em diversas situações. As informações e conclusões obtidas serão fundamentais para o desenvolvimento de sistemas de processamento 
			de vídeo mais eficientes e versáteis.</p>
		
		<h2> 2.Fundamentos Básicos</h2>

		<p>Ao estudar as Features, como proposto no laboratório, os conceitos fundamentais da visão computacional e processamento de imagens são colocados em 
			prática. A compreensão dos princípios de detecção de cantos e pontos distintivos, como os abordados nos exercícios do laboratório, fornece os 
			blocos de construção para identificar características visuais únicas em uma imagem. Isso é essencial para o reconhecimento de objetos, 
			rastreamento de movimento e outras aplicações em processamento de vídeo.</p>
		
		<p>O primeiro exercício, o "Harris Corner Detection," aborda a detecção de cantos em uma imagem. Ao entender os conceitos de gradiente de intensidade e 
			matriz de covariância, os estudantes aprendem como identificar pontos de interesse relevantes para a análise de uma cena.</p>
		
		<p>O segundo exercício, o "Shi-Tomasi Corner Detector & Good Features to Track," explora uma abordagem ligeiramente diferente para a detecção de cantos, 
			focando em selecionar os melhores pontos de interesse para o rastreamento em sequências de vídeo. Esse método é útil para aplicações de visão 
			computacional, como rastreamento de objetos em movimento.</p>
		
		<p>O terceiro exercício, a "Introduction to SIFT (Scale-Invariant Feature Transform)," apresenta um método avançado de detecção de pontos distintivos 
			invariantes à escala. Ao aprender sobre o conceito de pontos-chave e descritores, os estudantes adquirem uma compreensão mais aprofundada das 
			características invariantes e sua importância para a robustez dos algoritmos de visão computacional.</p>
		
		<h3>

		<h2> 3.Materiais e Métodos</h2>

		<h3>1. Ambiente dos experimentos</h3>

		<p>a) Sistema Operacional:</p>
		<p>- Ubuntu (versão 20.22)</p>

		<p>b) Equipamentos:</p>
		<p>- Computador com webcam integrada</p>
		<p>- Monitor de exibição</p>

		<h3>2. Programas e Bibliotecas utilizadas</h3>

		<p>a) Programas:</p>
		<p>- Python: Linguagem de programação utilizada para desenvolver os programas.</p>
		
		<p>b) Bibliotecas:</p>
		<p>- OpenCV (versão 4.7.0): Biblioteca principal para manipulação de imagens e vídeos.</p>
		<p>- NumPy (versão 1.21.5): Biblioteca para operações numéricas e processamento de arrays.</p>

		<h3>3. Código Fonte</h3>

		<h4> 1.1 Deteção de Features pelo método Harris Corner Detection. </h4>

        <p>Este código utiliza a biblioteca OpenCV (cv2) para detectar cantos em uma imagem usando o algoritmo de Harris Corner 
		Detection. A detecção é feita em uma imagem 'img2.jpg' que é convertida para escala de cinza. Os cantos são 
		marcados em vermelho na imagem original, e o resultado é exibido em uma janela. O usuário pode fechar a janela 
		pressionando a tecla 'ESC', e a imagem resultante é salva em um arquivo.
			<pre><code class="python">
import numpy as np
import cv2 as cv

filename = 'img2.jpg'

img = cv.imread(filename)
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
gray = np.float32(gray)
dst = cv.cornerHarris(gray, 2, 3, 0.04)

# result is dilated for marking the corners, not important
dst = cv.dilate(dst, None)

# Threshold for an optimal value, it may vary depending on the image.
img[dst > 0.01 * dst.max()] = [0, 0, 255]

# Create a named window and resize it
cv.namedWindow('dst', cv.WINDOW_NORMAL)
cv.resizeWindow('dst', 600, 1200)  # Change the size to your preferred dimensions

cv.imshow('dst', img)

cv.imwrite('img2_harris.jpg',img)


if cv.waitKey(0) & 0xff == 27:
    cv.destroyAllWindows()

			</code></pre>
		</p>

		<h4> 1.2 Deteção de Features pelo método  Shi-Tomasi Corner Detector & Good Features to Track. </h4>

        <p>Neste código, o OpenCV é usado para detectar cantos em uma imagem ('img2.jpg') usando o algoritmo Shi-Tomasi. Os 
		cantos são marcados na imagem original com círculos vermelhos e, em seguida, a imagem resultante é exibida em 
		uma janela gráfica.
			<pre><code class="python">
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('img2.jpg')
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

corners = cv.goodFeaturesToTrack(gray,25,0.01,10)
corners = np.int0(corners)

for i in corners:
 x,y = i.ravel()
 cv.circle(img,(x,y),3,255,-1)
 
plt.imshow(img),plt.show()

			</code></pre>
		</p>

		<h4> 1.3 Deteção de Features pelo método  Introduction to SIFT (Scale-Invariant Feature Transform). </h4>

        <p>Este código utiliza o OpenCV (cv2) para aplicar o algoritmo SIFT (Scale-Invariant Feature Transform) em uma imagem e, 
		em seguida, desenha os keypoints (pontos de interesse) encontrados na imagem original. A imagem resultante, com 
		os keypoints marcados, é salva como 'img2_sift.jpg'. O algoritmo SIFT é frequentemente usado para encontrar 
		pontos de interesse robustos em imagens, que podem ser usados em tarefas como correspondência de imagens e 
		reconhecimento de objetos.
			<pre><code class="python">
import numpy as np
import cv2 as cv

img = cv.imread('img2.jpg')
gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp = sift.detect(gray,None)

img=cv.drawKeypoints(gray,kp,img)

cv.imwrite('img2_sift.jpg',img)

			</code></pre>
		</p>

		<h4> 2.1 Deteção de Features com a leitura da webcam pelo método Harris Corner Detection. </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de cantos de Harris 
		em tempo real. Os cantos são marcados em vermelho na imagem exibida. Quando a tecla Enter é pressionada, uma 
		foto do frame atual é salva como 'img_harris.jpg'. Para sair do programa, basta pressionar a tecla 'q' durante 
		a exibição da imagem. Após a conclusão, a captura da câmera é liberada e todas as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    gray = np.float32(gray)
    dst = cv.cornerHarris(gray, 2, 3, 0.04)
    dst = cv.dilate(dst, None)

    frame[dst > 0.01 * dst.max()] = [0, 0, 255]

    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_harris.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()

			</code></pre>
		</p>

		<h4> 2.2 Deteção de Features com a leitura da webcam pelo método Shi-Tomasi Corner Detector & Good Features to 
			Track. </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de cantos usando o 
		algoritmo Shi-Tomasi em tempo real. Os cantos detectados são marcados em cada frame exibido. Quando a tecla 
		Enter é pressionada, uma foto do frame atual é salva como 'img_shi_tomasi.jpg'. Para sair do programa, basta 
		pressionar a tecla 'q' durante a exibição da imagem. Após a conclusão, a captura da câmera é liberada e todas 
		as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    corners = cv.goodFeaturesToTrack(gray,25,0.01,10)
    corners = np.int0(corners)

    for i in corners:
        x,y = i.ravel()
        cv.circle(frame,(x,y),3,255,-1)
 
    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_shi_tomasi.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()
			</code></pre>
		</p>

		<h4> 2.3 Deteção de Features com a leitura da webcam pelo método  Introduction to SIFT 
			(Scale-Invariant Feature Transform). </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de pontos de 
		interesse usando o algoritmo SIFT (Scale-Invariant Feature Transform) em tempo real. Os pontos de interesse 
		detectados são marcados em cada frame exibido. Quando a tecla Enter é pressionada, uma foto do frame atual é 
		salva como 'img_sift.jpg'. Para sair do programa, basta pressionar a tecla 'q' durante a exibição da imagem. 
		Após a conclusão, a captura da câmera é liberada e todas as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    sift = cv.SIFT_create()
    kp = sift.detect(gray,None)

    frame=cv.drawKeypoints(gray,kp,frame)
 
    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_sift.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()
			</code></pre>
		</p>
		
		<h2> 4.Resultados e Análises</h2>
		
		<h2> 5. Conclusões e Comentários Finais</h2>

		<p>O laboratório de Processamento de Vídeo sobre Features proporcionou uma compreensão sólida dos conceitos fundamentais de detecção de características 
			visuais. Através do estudo teórico e da aplicação prática dos algoritmos, aprendemos a identificar cantos, pontos distintivos e características 
			invariantes à escala em imagens e vídeos.</p>
			
		<p>Os Fundamentos Básicos desempenharam um papel crucial nesse processo, fornecendo a base necessária para explorar técnicas mais avançadas e desenvolver 
			habilidades em visão computacional. Através dos experimentos, pudemos avaliar a eficácia dos métodos de detecção e suas aplicações práticas.</p>
			
		<p>Olhando para o futuro, reconhecemos a importância contínua de aprofundar nosso conhecimento em Features e seus fundamentos. Isso nos permitirá 
			explorar novas tecnologias, como o Deep Learning.</p>
		
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
	<script>
		hljs.highlightAll();
	</script>
	</body>
</html>
