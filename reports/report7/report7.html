<html>
	<head>

	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">

	</head>

	<body>
		<h1> Relatório lab 7 </h1>

		<h2> Grupo </h2>

		<p>Leonardo Di Credico </p>

		<p>Anthony Hlebania</p>

		<p>Fernando Hiroaki Suzuki</p>

		<p>Fernando Astolfo Dos Santos</p>
		
		<h2> 1.Introdução </h2>

		<p>O presente relatório descreve o laboratório realizado na disciplina de Processamento de Vídeo, com foco 
			na detecção de objetos utilizando a técnica de Cascade Classifier. A detecção de objetos é uma 
			área fundamental da visão computacional, com aplicações abrangentes em diversos setores, desde a 
			segurança até a automação industrial.</p>

		<p>Ao longo do laboratório, foram estudados conceitos teóricos essenciais sobre detecção de objetos com o 
			Cascade Classifier, compreendendo a teoria por trás do funcionamento dessa técnica e sua 
			implementação prática. Além disso, foram explorados arquivos XML contendo modelos pré-treinados 
			para a detecção de objetos comuns, como rostos, olhos e sorrisos.</p>
		
		<p>Este relatório detalhará o estudo realizado durante o laboratório, descrevendo a teoria do Cascade Classifier,
			os passos de implementação dos programas e os resultados alcançados. Também serão apresentadas as 
			conclusões e considerações sobre o desempenho e as aplicações práticas da detecção de objetos por meio 
			dessa técnica.</p>
		
		<h2> 2.Fundamentos Básicos</h2>

		<p>A detecção de objetos é uma das principais tarefas na área de visão computacional. Trata-se de 
			identificar a presença e a localização de objetos específicos dentro de uma imagem ou sequência 
			de vídeo. Essa tarefa é fundamental em muitos campos, como reconhecimento facial, monitoramento 
			de segurança, condução autônoma, entre outros. O Cascade Classifier é uma abordagem eficiente para 
			a detecção de objetos em tempo real, especialmente quando se trata de objetos com características 
			bem definidas, como rostos humanos. A técnica se baseia em classificadores em cascata, que são 
			organizados hierarquicamente e empregam recursos de Haar para realizar a detecção de maneira 
			rápida e precisa.</p>
		
		<p>As características de Haar são elementos retangulares que representam a intensidade de uma região específica 
			em uma imagem. Elas são calculadas usando a diferença entre a soma de pixels em regiões retangulares 
			adjacentes. Essas características são eficientes para descrever a variação de intensidade em diferentes
			partes de um objeto.</p>
		
		<p>O Cascade Classifier consiste em uma sequência de classificadores organizados em cascata, onde cada 
			estágio é responsável por decidir se uma região da imagem contém ou não o objeto de interesse. 
			Cada classificador é uma árvore de decisão que utiliza recursos de Haar para realizar a 
			classificação. A grande vantagem dos classificadores em cascata é que eles podem descartar 
			rapidamente as regiões que não contêm o objeto, reduzindo drasticamente a quantidade de cálculos 
			necessários para a detecção. Isso torna a abordagem muito eficiente e adequada para aplicações em 
			tempo real.</p>
		
		<p>Uma das principais vantagens do Cascade Classifier é a disponibilidade de modelos pré-treinados para a 
			detecção de objetos comuns, como rostos, olhos, sorrisos, entre outros. Esses modelos são arquivos 
			XML que contêm as informações necessárias para o funcionamento dos classificadores em cascata. Os 
			modelos pré-treinados permitem que os desenvolvedores utilizem a detecção de objetos em suas 
			aplicações sem a necessidade de treinar um modelo do zero, economizando tempo e recursos 
			computacionais.</p>
		
		<h3>

		<h2> 3.Materiais e Métodos</h2>

		<h3>1. Ambiente dos experimentos</h3>

		<p>a) Sistema Operacional:</p>
		<p>- Ubuntu (versão 20.22)</p>

		<p>b) Equipamentos:</p>
		<p>- Computador com webcam integrada</p>
		<p>- Monitor de exibição</p>

		<h3>2. Programas e Bibliotecas utilizadas</h3>

		<p>a) Programas:</p>
		<p>- Python: Linguagem de programação utilizada para desenvolver os programas.</p>
		
		<p>b) Bibliotecas:</p>
		<p>- OpenCV (versão 4.7.0): Biblioteca principal para manipulação de imagens e vídeos.</p>
		<p>- NumPy (versão 1.21.5): Biblioteca para operações numéricas e processamento de arrays.</p>

		<h3>3. Código Fonte</h3>

		<h4> 1.1 Deteção de objetos utilizando o modelo Haarcascade Frontal Face (utilizado nos exercícios). </h4>

        <p>Este código detecta rostos em uma imagem ('avatares.png') usando o classificador Haar Cascade pré-treinado do 
		OpenCV. Ele desenha retângulos ao redor das faces detectadas e exibe a imagem resultante em uma janela 
		chamada "Faces Detection". Se pressionar a tecla 's', a imagem com os retângulos é salva no diretório. 
		Pressionar a tecla 'Esc' fecha todas as janelas.
			<pre><code class="python">
import cv2 
import numpy as np 
import common #some useful opencv functions

test_image = cv2.imread('avatares.png')
grey = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)

# Carrega a cascade treinada e na imagem cinza aplica Detecção de FACES:
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
faces = face_cascade.detectMultiScale(grey, 1.3, 5)

# na imagem de entrada desenha retangulos nos pontos detectados
for (x,y,w,h) in faces:
     cv2.rectangle(test_image,(x,y),(x+w,y+h),(255,0,0),2)

# Definir nome da janela para re-dimensionar a janela
height, width, ch = test_image.shape
W2 = int(width/1.5)
H2 = int(height/1.5)
cv2.namedWindow("Faces Detection", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Faces Detection", W2, H2)
cv2.imshow("Faces Detection", test_image)


if cv2.waitKey(0) == ord('s'):       
    cv2.imwrite('avatares_frontalface.png', test_image)
    cv2.destroyAllWindows()

if cv2.waitKey(0) & 0xff == 27:
 cv2.destroyAllWindows()

			</code></pre>
		</p>

		<h4> 1.2 Deteção de Features pelo método  Shi-Tomasi Corner Detector & Good Features to Track. </h4>

        <p>Neste código, o OpenCV é usado para detectar cantos em uma imagem ('img2.jpg') usando o algoritmo Shi-Tomasi. Os 
		cantos são marcados na imagem original com círculos vermelhos e, em seguida, a imagem resultante é exibida em 
		uma janela gráfica.
			<pre><code class="python">
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img = cv.imread('img2.jpg')
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)

corners = cv.goodFeaturesToTrack(gray,25,0.01,10)
corners = np.int0(corners)

for i in corners:
 x,y = i.ravel()
 cv.circle(img,(x,y),3,255,-1)
 
plt.imshow(img),plt.show()

			</code></pre>
		</p>

		<h4> 1.3 Deteção de Features pelo método  Introduction to SIFT (Scale-Invariant Feature Transform). </h4>

        <p>Este código utiliza o OpenCV (cv2) para aplicar o algoritmo SIFT (Scale-Invariant Feature Transform) em uma imagem e, 
		em seguida, desenha os keypoints (pontos de interesse) encontrados na imagem original. A imagem resultante, com 
		os keypoints marcados, é salva como 'img2_sift.jpg'. O algoritmo SIFT é frequentemente usado para encontrar 
		pontos de interesse robustos em imagens, que podem ser usados em tarefas como correspondência de imagens e 
		reconhecimento de objetos.
			<pre><code class="python">
import numpy as np
import cv2 as cv

img = cv.imread('img2.jpg')
gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp = sift.detect(gray,None)

img=cv.drawKeypoints(gray,kp,img)

cv.imwrite('img2_sift.jpg',img)

			</code></pre>
		</p>

		<h4> 2.1 Deteção de Features com a leitura da webcam pelo método Harris Corner Detection. </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de cantos de Harris 
		em tempo real. Os cantos são marcados em vermelho na imagem exibida. Quando a tecla Enter é pressionada, uma 
		foto do frame atual é salva como 'img_harris.jpg'. Para sair do programa, basta pressionar a tecla 'q' durante 
		a exibição da imagem. Após a conclusão, a captura da câmera é liberada e todas as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    gray = np.float32(gray)
    dst = cv.cornerHarris(gray, 2, 3, 0.04)
    dst = cv.dilate(dst, None)

    frame[dst > 0.01 * dst.max()] = [0, 0, 255]

    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_harris.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()

			</code></pre>
		</p>

		<h4> 2.2 Deteção de Features com a leitura da webcam pelo método Shi-Tomasi Corner Detector & Good Features to 
			Track. </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de cantos usando o 
		algoritmo Shi-Tomasi em tempo real. Os cantos detectados são marcados em cada frame exibido. Quando a tecla 
		Enter é pressionada, uma foto do frame atual é salva como 'img_shi_tomasi.jpg'. Para sair do programa, basta 
		pressionar a tecla 'q' durante a exibição da imagem. Após a conclusão, a captura da câmera é liberada e todas 
		as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    corners = cv.goodFeaturesToTrack(gray,25,0.01,10)
    corners = np.int0(corners)

    for i in corners:
        x,y = i.ravel()
        cv.circle(frame,(x,y),3,255,-1)
 
    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_shi_tomasi.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()
			</code></pre>
		</p>

		<h4> 2.3 Deteção de Features com a leitura da webcam pelo método  Introduction to SIFT 
			(Scale-Invariant Feature Transform). </h4>

        <p>Este código utiliza o OpenCV para acessar a câmera do computador (webcam) e realizar a detecção de pontos de 
		interesse usando o algoritmo SIFT (Scale-Invariant Feature Transform) em tempo real. Os pontos de interesse 
		detectados são marcados em cada frame exibido. Quando a tecla Enter é pressionada, uma foto do frame atual é 
		salva como 'img_sift.jpg'. Para sair do programa, basta pressionar a tecla 'q' durante a exibição da imagem. 
		Após a conclusão, a captura da câmera é liberada e todas as janelas são fechadas.
			<pre><code class="python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    sift = cv.SIFT_create()
    kp = sift.detect(gray,None)

    frame=cv.drawKeypoints(gray,kp,frame)
 
    # Display the resulting frame
    cv.imshow('frame', frame)

    # Salva a foto do frame quando a tecla Enter for pressionada 
    if cv.waitKey(1) == 13:
        cv.imwrite('img_sift.jpg', frame)
        break

    # Check if the 'q' key is pressed to quit the loop
    if cv.waitKey(1) == ord('q'):
        break

# When everything is done, release the capture
cap.release()
cv.destroyAllWindows()
			</code></pre>
		</p>
		
		<h2> 4.Resultados e Análises</h2>

		<h3> 1.1 Deteção de objetos utilizando o modelo Haarcascade Frontal Face (utilizado nos exercícios). </h3>

	<h4> Imagens Originais: </h4>

		<figure>
			<img src="src/1/grupo.png" height="480"/>
	    	</figure>

		<figure>
			<img src="src/1/avatares.png" height="480"/>
	    	</figure>
			
        <h4> Haarcascade Frontal Face </h4>
            
            <figure>
		<img src="src/1/grupo_frontalface.png" height="480"/>
	    </figure>

	    <figure>
		<img src="src/1/grupo_frontalface.png" height="480"/>
	    </figure>

		<h3> 1.2 Deteção de Features pela leitura da webcam</h3>

	<h4> Harris Corner Detection </h4>
			
		<figure>
			<img src="src/2/fernandoa_harris.jpg" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/fernandos_harris.jpg" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/leonardo_harris.jpg" height="480"/>
	    	</figure>

	<h4> Shi-Tomasi Corner Detector & Good Features to Track </h4>
			
		<figure>
			<img src="src/2/fernandoa_shi_tomasi.png" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/fernandos_shi_tomasi.jpg" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/leonardo_shi_tomasi.jpg" height="480"/>
	    	</figure>

	<h4> Introduction to SIFT (Scale-Invariant Feature Transform) </h4>
			
		<figure>
			<img src="src/2/fernandoa_sift.jpg" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/fernandos_sift.jpg" height="480"/>
	    	</figure>

		<figure>
			<img src="src/2/leonardo_sift.jpg" height="480"/>
	    	</figure>

			
		<h2> 5. Conclusões e Comentários Finais</h2>

		<p>O laboratório de Processamento de Vídeo sobre Features proporcionou uma compreensão sólida dos conceitos fundamentais de detecção de características 
			visuais. Através do estudo teórico e da aplicação prática dos algoritmos, aprendemos a identificar cantos, pontos distintivos e características 
			invariantes à escala em imagens e vídeos.</p>
			
		<p>Os Fundamentos Básicos desempenharam um papel crucial nesse processo, fornecendo a base necessária para explorar técnicas mais avançadas e desenvolver 
			habilidades em visão computacional. Através dos experimentos, pudemos avaliar a eficácia dos métodos de detecção e suas aplicações práticas.</p>
			
		<p>Olhando para o futuro, reconhecemos a importância contínua de aprofundar nosso conhecimento em Features e seus fundamentos. Isso nos permitirá 
			explorar novas tecnologias, como o Deep Learning.</p>
		
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
	<script>
		hljs.highlightAll();
	</script>
	</body>
</html>
